---
layout: post
title:  "性能之巅读书笔记"
date:   2019-04-14 20:05:00 +0800
author: Siglud
categories:
  - 读书笔记
tags:
  - Linux
comment: true
share: true
---

## 引子
读书过后不写点什么，总会感觉最后回味下来（特别是几个月甚至几年后）只是记得——“嗯，我读过这个书”，甚至连里面的内容都忘得七七八八，虽然好书确实是需要反复的读才有效果，但是为了方便之后反复读的时候能够快速的提纲挈领，还是边读边记录一下。于是算是个读书笔记，同步记录一下读书的进度（本文持续更新直到这段文字消失）

## 绪论
绪论只是告诉我们，什么是性能，为什么性能是充满挑战的。举的两个实例也算是很通俗易懂。

## 方法
这一章主要是一些用于统计性能的方法、一些用来查找性能问题的方法论（包括正确和错误的），主要是涉及到一些统计学的测量方法

顺带总结一下课后习题

1. 什么是IOPS？

    原书14页：每秒发生的输入/输出操作的次数，是数据传输的一个度量方法。对于磁盘的读写，IOPS指的是每秒读和写的次数。
1. 什么是使用率和饱和度

    原书14页：使用率，对于服务所请求的资源，使用率描述在所给定的时间区间内资源的繁忙程度。对于存储资源来说，使用率指的就是所消耗的存储容量；饱和度：指的是某一资源无法满足服务的排队工作量（例如在Job List中的排队数值）

1. 什么是延时

    原书14页：延时是描述操作里用来等待服务的时间。

1. 什么是微基准

    原书48页：微基准测试测量的是施加了简单的额人造负载的性能。微基准测试可以用于支持科学方法，将假设和预测放到测试中验证。或者作为容量规划的一部分来执行。

    这玩意怎么理解呢……嗯，其实有人做[Java的微基准测试](https://www.xncoding.com/2018/01/07/java/jmh.html)，我在之前的Blog里面也测试过Java8的Steam的性能，其实那个也算是微基准测试了。

1. 选择五种方法运用到你的环境里（或者是构想的环境）。确定它们的执行顺序，并且解释选择这些方法的原因。

    原文列举了21种方法，除了街灯讹、随机变动讹、责怪他人讹之外，其实都是很实用的方法。

    问题发生了，第一件事情当然是搞定问题的由来，所以第一件事就是问清楚问题是什么造成的，自然第一件事是选择“问题陈述法”——即问以下几个问题：
    1. 是什么让你认为存在性能问题？
    1. 系统之前运行得好么？
    1. 最近有什么改动？软件？硬件？负载？
    1. 问题能用延时或者运行时间来表述么？
    1. 问题影响到了其他的人和应用程序了吗？
    1. 环境是怎么样的？用了哪些硬件和软件？是什么版本？是怎么样的配置？

    因为我并不是专业做性能调优的，而如果有Ad Hoc清单，我自然是先去做Ad Hoc，对着单子逐一检查所有的问题无疑是最快最便捷的方法。

    如果这个还搞不定，那只能尝试作者比较推荐的USE方法，即对于所有的资源，查看它的使用率、饱和度和错误。一般到了这个级别，问题基本上就能定位到哪里了

    接下来如果查出来是资源限制可以考虑采用科学法，如果定位还不够准确可以考虑工具法，如果是代码的问题考虑延时分析或者微基准测试，如果如果定位到外部软件资源的问题也可以采用事件跟踪。

1. 总结把平均延时作为唯一的性能指标会有哪些问题。这些问题能够通过加入第99百分位数得到解决吗？

    原书62页：平均值以及百分位数都是针对正常分布或者说单模态分布而言的。系统性能经常会出现双模态的情况，对快速的代码路径是低延时、缓慢的代码路径是高延时的，或者对于缓存命中的情况是低延时、缓存失效的情况是高延时，也会有多于两种模态的情况。

    所以记得在看到性能指标中的平均值的时候，记得也要问一下：分布是怎么样的？

## 操作系统
这章一开头有点懵……

第74页：
```
内核空间：内核的内存地址空间
用户空间：进程的内存地址空间
用户空间：用户级别的程序和库（←？？黑人问号
```
怎么两个用户空间？翻原版看看，原来一个是User-space一个是User-land。

其他的似乎都没什么好讲的，之前看的《Linux内核设计与实现》基本上也讲了，这章算是简单的用几句话浓缩了一下。不过作者说Linux内核的系统调用总数越来越多，而与此同时Solaris的系统调用则是越来越少，确实是比较有意思的一个情况。

继续课后习题（选做）：

1. 什么是上下文切换？

    原书74页，内核程序切换CPU让其在不同的地址空间上做操作（Context）
1. Paging与Swapping之间的区别是什么？

    原书84页，Swapping：让整个进程在内存和二级存储之间做移动；Paging：移动称为页的小的内存单元。swapping是原始的UNIX方法，会引起严重的性能损耗。Paging是更高效的方法，经由换页虚拟内存的引入而加入到了BSD中。两种方法，最近最少用（LRU）的内存被移动到二级存储，仅在需要的时候再次搬回内存。在Linux里，Swapping用于指代Paging，Linux内核不支持UNIX风格的整体线程和进程的Swapping（Paging）。
1. I/O密集型和CPU密集型工作负载之间有什么区别？

    原书85页，CPU密集型一般属于运行时间比较长，CPU用量比较大的工作；I/O密集型一般是CPU用量不大，计算不多，更多的是请求文件系统、Socket之类的外部资源。
1. 描述一下内核的作用

    原书74页，内核管理CPU调度、内存、文件系统、网络协议以及系统设备（磁盘、网络接口）。通过系统调用提供访问设备和内核服务的机制。
1. 描述一下系统调用的作用

    原书81页，请求内核执行特权的系统例程（routines）。
1. 描述一下VFS的作用和它在I/O栈所处的位置

    原书86页，VSF是一个对文件系统类型做抽象的内核界面，VFS接口让内核添加新的文件系统更加简单。VFS位于I/O栈的系统调用之下、文件系统之上。
1. 列出线程离开CPU的原因

    线程运行结束、线程被阻塞时线程会离开CPU，结束可能是因为被杀死或者正常结束，阻塞可能是因为I/O阻塞、锁、也可能是CPU调度、抢占引起的
1. 描述一下虚拟内存和按需换页的有点。

    虚拟内存提供了逻辑上近似无限的内存空间，保证应用程序在内存紧张的情况下还能继续运行。按需换页避免了在内存和虚拟内存中的大量的数据迁移的性能损耗，，既能缓解内存紧张的问题，也能减少由此带来的性能损耗。

## 观测工具
本章主要是介绍一些常用的检测功能以及操作系统中这些数据的来源，系统的介绍了一些常用的系统工具和他们的数据来源（后者对于本章来说更为重要，因为工具本身的使用方法后面的章节都会详细的讲，但是数据来源只有这章会讲），Linux的主要输来源是/proc和/sys

继续回答课后习题：

1. 什么是剖析？

    原书102页，Profiling是通过对目标收集采样活快照来归纳目标特征，一个常见的例子就是CPU的使用率，对程序计数器采样，或者跟踪栈来找到消耗CPU周期的代码路径。
1. 什么是跟踪？

    原书101页，跟踪收集每一个时间的数据以供分析。日志，包括系统日志可以认为是一种默认开启的低频率跟踪。
1. 静态跟踪和动态跟踪有什么区别？

    原书116页，动态跟踪是只有开启之后才能插入指令。，没开启时，是没有附加指令的，因此也没有任何探针效果，这就是不使用时零开销。与此对应的，静态跟踪就是永远开启的跟踪

## 应用程序
本章主要是讲了一下我日常所关注的一些地方了，毕竟写的就是应用程序嘛，有些东西还是蛮重要的（虽然已经知道，但是还是要点一下）：

性能相关的几个目标：
1. 延时：降低应用程序的响应时间
1. 吞吐量：高应用程序操作率或者数据传输率
1. 资源使用率：对于给定应用程序工作负载，高效地使用资源

优化点也就是传统的几个大棒：读缓存、写缓存、并发、并行、异步、锁优化（自旋锁、类似Java的CurrentHashMap一样的哈希表锁），当然，也有高级的我现在没有写到过的了，比如CPU绑定（只在Nginx的设置里面见过）

课后习题有点多，挑点写写吧

1. 什么是缓存

    原书138页，将执行结果保存在本地缓存中以备后用，而非总是执行开销较高的操作。其实我这边感觉它定义的缓存都是单指读缓存，写缓存它会称之为缓冲区（一个是Cache，一个是Buffer）
1. 什么是唤醒缓冲区？

    原书138页，环形缓冲区（或者循环缓冲区）是一类用于组件之间连续数据传输的大小固定的缓冲区，缓冲区的操作是异步的。该类型缓冲可以用头指针和尾指针来实现，指针随着数据的增加或者移出而改变位置。也就是说，这东西一定不会缓冲区溢出，真的到了要溢出的时候，它会覆盖（丢弃）掉之前的值。
1. 什么是自旋锁？

    原书139页，自旋锁只允许持有者操作，其他的需要自旋锁的线程会在CPU上循环自旋，检查锁是否被释放。虽然这样可以提供低延时的访问，被阻塞的线程不会离开CPU，时刻准备着运行直到锁可用，但是线程自旋、等待也是对CPU资源的浪费。其实就是已给死循环拼命的检查锁拿到没有，这种的锁一般都有自旋的阈值适用于锁不是很频繁的场景，但是切不可用于递归调用拿锁（会显著的锁死自己，当然了，可以有办法规避）
1. 什么是自适应Mutex锁

    原书140页，首先解释一下Mutex锁，只有锁的持有者才能操作，其他线程阻塞并等待CPU叫Mutex锁，然后使用库或者内核实现成为自适应Mutex锁（adaptive mutex lock）这是自旋锁和Mutex锁的混合，当锁的持有者正运行在另一个CPU上的时候，线程会自旋，如果不是，线程会阻塞（或者自旋的阈值到了）。自适应的Mutex锁已经在Unix上使用了很多年，在09年的时候移植到了Linux，称之为自适应自旋锁。其实原理也挺简单的，如果你在另一个CPU上运行，你自旋才有意义，如果你在和持有锁的人的同一个CPU上运行，那么自然是拿不到锁或者是该你拿的时候把你调度起来自然就拿到了，强制性的去自旋只会增加一些无谓的开销，这个就是减少这个开销的锁机制。
1. 并发和并行有什么区别？

    首先要解释一下这两个词，一个是Concurrency，一个是Parallelism，中文看起来好像差不多，英文就好理解多了（完全长得不一样好不好！）原书139页，Concurrency的意思是装载和运行多个可运行程序的能力，虽然他们的运行时间是重叠的，但是并不一定在同一瞬间都在CPU上执行，每一个这样的程序都可以是一个应用程序进程。传统的实现方式是多进程或者多线程，当然也有基于事件的并发，书中举了NodeJs的例子，其实还有Go的Goroutine或者Java的Reactor都是这样的东西。Parallelism是应用程序同时间运行在多个CPU上的能力，这个一般只能用多线程或者多进程来实现。总的来说就是如果你只有一个CPU，那铁定跟Parallelism是无缘了，但是如果有多个CPU，你如果能同时使用多个CPU，说明你能Parallelism，如果你能够在一个CPU上也能多任务同时跑，说明你能Concurrency
1. 什么是CPU亲和性？

    原书141页，NUMA环境对进程或者线程保持运行在一颗CPU上是有优势的，线程执行I/O之后，能像执行I/O之前那样运行在同一CPU上，能提高应用程序的内存本地性，减少内存I/O，并提高应用程序的整体性能。操作系统对此很清楚的，设计的本意就是让应用程序线程依附在同一颗CPU上。作者也介绍了这种亲和性在云计算时的坑，因为绑定的CPU如果正忙于其他的租户，而追加了亲和性的应用程序可能不会去使用空闲的CPU而是一直等待之前的CPU有可能会导致性能下降。
1. 使用大尺寸I/O的优点和缺点是什么？

    原书137页，因为“初始化开销”对大型和小型的I/O都差不多，从效率上来说，每次I/O传输的数据越多，效率就会越高，因此增加IO的尺寸是应用程序提高吞吐量的常用策略，考虑到每次I/O的固定开销，一次传输128KB自然要高于128次传输1KB，尤其对于磁盘I/O，由于存在寻道时间，每次I/O的开销都较高（这就是为什么主动的mmap速度一般会快于Stream的方式的原因之一）。缺点是，如果应用程序不需要，更大的I/O尺寸也会带来负面效应，一个执行8KB随机读取的数据库按128KB I/O的尺寸运行会慢得多，因为有120KB的数据传输能力被浪费了，选择小一些的I/O尺寸，更贴近应用程序所需，能够降低引起的I/O延时，不必要的大尺寸I/O还会浪费缓存空间。
1. 锁的哈希表用处是什么？

    原书140页，哈希表锁是为所有的数据设置一个全局的Mutex锁和为每一个数据结构设置一个Mutex锁的一个折中方案，当期望锁的竞争能轻一些的时候很适用。创建固定数目的锁，用哈希算法来选择哪个锁用于哪个数据结构。这就避免了随数据结构创建和销毁锁的开销，也避免了只使用单个锁的问题。简单的说就是创建一个类似Java里面ConcurrentHashMap的一个结构（作者提到了哈希冲突的时候链表和树结构切换的过程，简直是像极了ConcurrentHashMap），使用类似于它的机制去加锁，避免每一个都创建锁，也避免大家都去抢同一个锁造成的串行化。另外，这个Hash表锁的Bucket至少要大于或者等于物理CPU的数量。
1. 讲一下编译语言、解释语言和虚拟机语言运行时大致的性能特征。

    原书142页~144页，编译语言是运行之前将程序生成机器指令，保存在二级制可执行文件中，这些文件可以在任何时间运行而无需再度编译。编译之后的代码总体来说是高性能的，在被CPU执行之前不需要进一步转换。因为所执行的机器代码总是和原始代码映射得很紧密，所以编译语言的性能分析通常是很直观的（从操作系统层面直接观察而言）。解释语言的执行是将语言在运行时翻译为行为，这一行为会增加执行的开销。解释语言并不期望能够表现出很高的性能，而是用于其他因素更为重要的情况下，比如编程和调试，除非提供专门的观测工具，否则对解释语言做性能分析是很苦难的。语言虚拟机，提供了平台独立的编程环境，应用程序先编译成虚拟机指令集，再有虚拟机执行这样的编译的对象。字节码是从原始程序编译而来，再由语言虚拟机进行解释的。解释时会把字节码转化为机器码。Java HotSpot虚拟机就支持JIT编译，提前将字节码编译成机器码，这样在执行期间运行的就是本机的机器码。这样的做法带来了编译后的代码性能上的优势。但是这样虚拟机一般是语言类型里最难观测的。性能分析通常依靠的是语言虚拟机提供的工具集和第三方工具。
1. 解释垃圾回收的作用，以及它是如何影响性能的。

    原书144页，一些语言使用自动内存管理，分配的内存不需要显示的释放，留给异步的垃圾收集来处理，虽然这让程序更容易编写，但也有缺点，主要表现为：
    1. 内存增长：针对应用程序内存使用的控制不多，当没能自动识别出对象适合被释放时内存的使用会增加，如果应用程序用的内存变得太大，达到了程序的极限或者引起系统换页，就会严重的损害性能。（简单的说就是垃圾收集没有能够正确的回收内存的话，会导致一些性能问题，比如内存泄露）
    1. CPU成本：GC通常会间歇的运行，还会搜索和扫描内存中的对象，这会消耗CPU资源，短期内能够提供给应用程序的CPU资源变少了，随着应用程序使用的内存增多，GC对CPU的消耗也会增加。在某些情况下，可能会出现GC不断消耗整个CPU的现象（比如JAVA GC的根搜索算法就会消耗CPU资源）
    1. 延时异常值：GC执行期间应用程序的执行可能会中止，偶尔出现高延时的响应，也取决于GC的类型，全停、增量或者并发（取决于STP的时间长短）

## CPU
这章基本上都在说CPU相关的基本概念，有些还是很重要的，比如CPU频率，看起来CPU使用量100%了，但是提高频率并不一定能够起到加快运行速度的作用，为什么呢？因为这个主要需要看CPU在这个周期内到底在做什么，CPU指令主要分成以下几个类型：
1. 指令预取
1. 指令解码
1. 执行
1. 内存访问
1. 寄存器写回
其中最后两个是可选的，有些指令仅仅操作寄存器，并不访问内存，所以如果CPU负荷为100%，但它大部分时间是停滞等待内存访问，那么更快的执行其实并不能提高CPU指令的执行效率或者负载的吞吐量。因为通常，内存访问是最慢的，需要几十个时钟周期。

（待续……）